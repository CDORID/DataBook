{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regrouping knowledge in an automatized way for binary classification\n",
    "\n",
    "\n",
    "Starting point:\n",
    "X and Y are formatted\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "\n",
    "import os\n",
    "import matplotlib as plt\n",
    "\n",
    "import sklearn as sk\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import xgboost as xgb \n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Data/titanic/train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### get the inner join of sales and controls\n",
    "\n",
    "\n",
    "X = df.drop('Survived', axis =1)\n",
    "Y = df['Survived']\n",
    "hypo = X.columns\n",
    "test = Y.columns\n",
    "\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.25, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imbalance:\n",
    "#### Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous split : \n",
      "0 :  415 \n",
      "1 :  253\n",
      "New split : \n",
      "0 :  200 \n",
      "1 :  253\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def undersample(X_train,Y_train, target_var = str, minor_class = 1, limit_sample = 200):\n",
    "    \"\"\"\n",
    "    Simple undersampling, test keep the same proportion\n",
    "    \n",
    "    \"\"\"\n",
    "    # Rebuild training set\n",
    "    training_set = pd.concat([X_train,Y_train],axis = 1)\n",
    "    \n",
    "    # Choose major class, and minor class as 1 and 0s\n",
    "    major_class = 1-minor_class\n",
    "    print(\"Previous split : \\n0 : \",training_set[training_set[target_var] == 0].shape[0],\"\\n1 : \",\n",
    "          training_set[training_set[target_var] == 1].shape[0])\n",
    "    \n",
    "    \n",
    "    #Define which values will be removed randomly\n",
    "    major_indices  = training_set[training_set[target_var] == major_class].index\n",
    "    minor_indices = training_set[training_set[target_var] == minor_class].index\n",
    "    random_indices = np.random.choice(major_indices, limit_sample, replace=False)\n",
    "    kept_indices = np.sort(np.append(minor_indices,random_indices))\n",
    "\n",
    "                             \n",
    "    #Redefine the training set according to the undersampling\n",
    "    training_set_undersampled  = training_set.loc[kept_indices]\n",
    "\n",
    "\n",
    "    print(\"New split : \\n0 : \",training_set_undersampled[training_set_undersampled[target_var] == 0].shape[0],\"\\n1 : \",\n",
    "          training_set_undersampled[training_set_undersampled[target_var] == 1].shape[0])\n",
    "    \n",
    "\n",
    "    training_set_undersampled\n",
    "    X_train_under = training_set_undersampled.drop(target_var, axis =1)\n",
    "    Y_train_under = training_set_undersampled[target_var]\n",
    "    \n",
    "    return X_train_under, Y_train_under\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous split : \n",
      "0 :  415 \n",
      "1 :  253\n",
      "New split : \n",
      "0 :  200 \n",
      "1 :  253\n"
     ]
    }
   ],
   "source": [
    "X_trainu, Y_trainu = undersample(X_train,Y_train,\"Survived\",1,200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Models being tested \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "\n",
    "## log regs\n",
    "log_reg = LogisticRegression(random_state=0, class_weight = 'balanced')\n",
    "log_reg_elastic = LogisticRegression(class_weight = 'balanced',penalty= 'l1',solver = 'liblinear')\n",
    "log_reg_l1 = LogisticRegression(class_weight = 'balanced',penalty= 'elasticnet',solver= 'saga',l1_ratio=0.5) #saga solver works\n",
    "\n",
    "## svc\n",
    "svc_lin = svm.SVC(class_weight = 'balanced',kernel = 'linear',probability=True)\n",
    "svc_poly = svm.SVC(class_weight = 'balanced',kernel = 'poly',probability=True)\n",
    "svc_rbf = svm.SVC(class_weight = 'balanced',kernel = 'rbf',probability=True)\n",
    "svc_sigmoid = svm.SVC(class_weight = 'balanced',kernel = 'sigmoid',probability=True)\n",
    "\n",
    "## NB\n",
    "multi_NB = MultinomialNB()\n",
    "\n",
    "## Decision tree\n",
    "dec_tree = DecisionTreeClassifier(class_weight = 'balanced')\n",
    "xgboost = XGBClassifier(eval_metric ='auc'#scale_pos_weight = 5\n",
    "                       ) ###to be explained, its the ratio of imbalance\n",
    "\n",
    "## Ensemble \n",
    "adab = AdaBoostClassifier()\n",
    "random_forest = RandomForestClassifier(class_weight=\"balanced\")\n",
    "\n",
    "## LDA\n",
    "lda = LinearDiscriminantAnalysis() ##svd\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def compute_AUC(model,X_test,Y_test):\n",
    "\n",
    "    yroc = Y_test.as_matrix().reshape(Y_test.as_matrix().size,1)\n",
    "    predroc = model.predict_proba(X_test)[:,1]\n",
    "    AUC = metrics.roc_auc_score(yroc, predroc)\n",
    "    return AUC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute ratios from confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Model_KPI:\n",
    "    \n",
    "    def __init__(model,model_name,X_test,Y_test):\n",
    "        \n",
    "        pred_proba_df = pd.DataFrame(model.predict_proba(X_test))\n",
    "        ## redundance in dataframe creation before\n",
    "        threshold_list = np.arange(0.0, 1.0, 0.005).tolist()\n",
    "        Laccuracy = []\n",
    "        Precision_list = []\n",
    "        Lmissclassified_1 = []\n",
    "        TNR_list = []\n",
    "        TPR_list = []\n",
    "\n",
    "        j = 0\n",
    "\n",
    "    def compute()\n",
    "        point_equilibrium = 0\n",
    "        delta_tpr_tnr_equilibrium = 1\n",
    "\n",
    "        for i in threshold_list:\n",
    "            j = j+1\n",
    "\n",
    "\n",
    "            ## confusion matrix computation\n",
    "            Y_test_pred = pred_proba_df.applymap(lambda x: 1 if x > i else 0)\n",
    "            test_accuracy = metrics.accuracy_score(Y_test.as_matrix().reshape(Y_test.as_matrix().size,1),\n",
    "                                                   Y_test_pred.iloc[:,1].as_matrix().reshape(Y_test_pred.iloc[:,1].as_matrix().size,1))\n",
    "\n",
    "            confusion = metrics.confusion_matrix(Y_test.as_matrix().reshape(Y_test.as_matrix().size,1),\n",
    "                                   Y_test_pred.iloc[:,1].as_matrix().reshape(Y_test_pred.iloc[:,1].as_matrix().size,1))\n",
    "\n",
    "\n",
    "            # ratio computation\n",
    "            missclassified_1 = (confusion[1,0]/(confusion[1,0] + confusion[0,0]))\n",
    "            precision =  (confusion[1,1]/(confusion[1,1] + confusion[0,1])) \n",
    "            ratio_well_class = (confusion[1,1]+confusion[0,0])/(confusion[0,1]+confusion[1,1]+confusion[0,0]+confusion[1,0])\n",
    "            TNR = (confusion[0,0]/(confusion[0,1] + confusion[0,0]))\n",
    "            TPR =  (confusion[1,1]/(confusion[1,1] + confusion[1,0])) \n",
    "\n",
    "            ### find point of equilibrium \n",
    "\n",
    "            if abs(TPR-TNR) < delta_tpr_tnr_equilibrium:\n",
    "                point_equilibrium = np.mean([ratio_well_class,ratio_well_class,ratio_well_class]\n",
    "                delta_tpr_tnr_equilibrium = abs(TPR-TNR) \n",
    "\n",
    "\n",
    "            ### list appending to add the individual risk result        \n",
    "            Precision_list.append(precision)\n",
    "            Laccuracy.append(ratio_well_class)\n",
    "            Lmissclassified_1.append(missclassified_1)\n",
    "            TNR_list.append(TNR)\n",
    "            TPR_list.append(TPR)\n",
    "\n",
    "    \n",
    "    ### Df for all the risks for the model\n",
    "    Accuracy = pd.DataFrame({'risk':threshold_list, model_name : Laccuracy}) \n",
    "    Missclassified_1 = pd.DataFrame({'risk':threshold_list, model_name : Lmissclassified_1}) \n",
    "    Precision_df_1 = pd.DataFrame({'risk':threshold_list, model_name : Precision_list}) \n",
    "    TNR_df_1 = pd.DataFrame({'risk':threshold_list, model_name : TNR_list}) \n",
    "    TPR_df_1 = pd.DataFrame({'risk':threshold_list, model_name : TPR_list}) \n",
    "    \n",
    "    return Accuracy,Precision_df_1,Missclassified_1,TNR_df_1, TPR_df_1\n",
    "\n",
    "#compute_KPIs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "models = [log_reg,\n",
    "          log_reg_elastic,\n",
    "          log_reg_l1,\n",
    "          svc_lin,\n",
    "          svc_poly,\n",
    "          svc_rbf,\n",
    "          svc_sigmoid,\n",
    "          multi_NB,\n",
    "          dec_tree,\n",
    "          xgboost,\n",
    "          adab, #not adapted\n",
    "          random_forest,\n",
    "          lda      \n",
    "]\n",
    "\n",
    "undermodel = [multi_NB,\n",
    "             xgboost,\n",
    "             adab,\n",
    "             lda\n",
    "             ]\n",
    "\n",
    "\n",
    "\n",
    "CV = 4\n",
    "cv_df = pd.DataFrame(index=range(CV * len(models)))\n",
    "entries = []\n",
    "fitted_models = []\n",
    "i = 0\n",
    "\n",
    "\n",
    "### Initializing dataframe to store kPIS\n",
    "\n",
    "Accuracy_df = pd.DataFrame({\"risk\":np.arange(0.0, 1.0, 0.005).tolist()})\n",
    "Precision_df = pd.DataFrame({\"risk\":np.arange(0.0, 1.0, 0.005).tolist()})\n",
    "Missclassified_1_df = pd.DataFrame({\"risk\":np.arange(0.0, 1.0, 0.005).tolist()})\n",
    "TNR_df = pd.DataFrame({\"risk\":np.arange(0.0, 1.0, 0.005).tolist()})\n",
    "TPR_df = pd.DataFrame({\"risk\":np.arange(0.0, 1.0, 0.005).tolist()})\n",
    "\n",
    "### initializing list for individual kpis\n",
    "AUC_list = []\n",
    "\n",
    "for model in models:\n",
    "    \n",
    "    ## report models \n",
    "    i = i+1\n",
    "    model_name = str(str(i) +\"-\"+ model.__class__.__name__)\n",
    "    print(model_name)\n",
    "    \n",
    "   \n",
    "    ### verify the data input on undersampling\n",
    "    if model in undermodel : \n",
    "        \n",
    "        ### We use the undersampled data\n",
    "        accuracies = cross_val_score(model, Xunder, Yunder, scoring='accuracy', cv=CV)\n",
    "        \n",
    "        fitted_model = model.fit(X_train_under,Y_train_under)\n",
    "        prediction_train = model.predict(X_train_under)\n",
    "        \n",
    "        ## compute KPIs\n",
    "        AUC = compute_AUC(model,X_test_under,Y_test_under)\n",
    "        Accuracy,Precision_df_1,Missclassified_1,TNR_df_1,TPR_df_1 = compute_KPIs(fitted_model,model_name,X_test_under,Y_test_under)\n",
    "        \n",
    "    else : \n",
    "        ## cross_val accuracies\n",
    "        accuracies = cross_val_score(model, X, Y, scoring='accuracy', cv=CV)\n",
    "        \n",
    "        fitted_model = model.fit(X_train,Y_train)\n",
    "        prediction_train = model.predict(X_train)\n",
    "        \n",
    "        ## compute KPIs\n",
    "        AUC = compute_AUC(model,X_test,Y_test)\n",
    "        Accuracy,Precision_df_1,Missclassified_1,TNR_df_1,TPR_df_1 = compute_KPIs(fitted_model,model_name,X_test, Y_test)\n",
    "    \n",
    "    \n",
    "    #### \n",
    "    #Creating DF with results for all models\n",
    "    ####\n",
    "    \n",
    "    Accuracy_df = pd.concat([Accuracy_df, Accuracy],axis = 1)\n",
    "    Precision_df = pd.concat([Precision_df, Precision_df_1],axis = 1)\n",
    "    Missclassified_1_df = pd.concat([Missclassified_1_df, Missclassified_1],axis = 1)\n",
    "    TNR_df = pd.concat([TNR_df, TNR_df_1],axis = 1)\n",
    "    TPR_df = pd.concat([TPR_df, TPR_df_1],axis = 1)\n",
    "    \n",
    "    ###\n",
    "    # Creating list for indiv KPIs /model\n",
    "    ###\n",
    "    \n",
    "    AUC_list.append(AUC)\n",
    "    \n",
    "    number_bads = sum(prediction_train)\n",
    "   \n",
    "    for fold_idx, accuracy in enumerate(accuracies):\n",
    "        entries.append((model_name, fold_idx, accuracy,number_bads))\n",
    "        \n",
    "    fitted_models.append(fitted_model)\n",
    "    \n",
    "## removing redundant columns of indexes\n",
    "Accuracy_df= Accuracy_df.loc[:,~Accuracy_df.columns.duplicated()]\n",
    "Precision_df= Precision_df.loc[:,~Precision_df.columns.duplicated()]\n",
    "Missclassified_1_df= Missclassified_1_df.loc[:,~Missclassified_1_df.columns.duplicated()]\n",
    "TNR_df = TNR_df.loc[:,~TNR_df.columns.duplicated()]\n",
    "TPR_df = TPR_df.loc[:,~TPR_df.columns.duplicated()]\n",
    "\n",
    "print(\"\\n\",i, 'Model Tested')\n",
    "\n",
    "cv_df = pd.DataFrame(entries, columns=['model_name', 'fold_idx', 'accuracy','number_bads'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
